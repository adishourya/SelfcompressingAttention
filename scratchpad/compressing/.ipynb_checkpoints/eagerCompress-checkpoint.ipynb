{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e6e1af-3f4d-43ed-9d72-a2cca6ec5e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sympy as sp\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotx\n",
    "plt.style.use(matplotx.styles.pacoty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c7df98-1998-490c-ad31-e69726113db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 feature input . 4 class labelling\n",
    "class Dataset():\n",
    "    def __init__(self, num_examples=100):\n",
    "        \"\"\"\n",
    "        4-class Classification dataset\n",
    "        W : R12 -> R4\n",
    "        y = argmax(X@W + b)\n",
    "        \"\"\"\n",
    "\n",
    "        torch.manual_seed(10)\n",
    "        \n",
    "        # Mostly sparse W with small scale and precision to represent them\n",
    "        # this could be inferenced with fp4 if our model achieves this.\n",
    "        self._W = torch.tensor([\n",
    "            [-0.15, 0.0,   0.0,   0.0],\n",
    "            [ 0.0, 0.15,  0.0,   0.0],\n",
    "            [ 0.05, 0.0,  0.0,   0.0],\n",
    "            [ 0.0, -0.1,  0.0,   0.0],\n",
    "            [ 0.0, 0.0,   0.0,   0.22],\n",
    "            [ 0.0, 0.0,   0.0,   0.0],\n",
    "            [ 0.0, 0.0,   0.0,  0.21],\n",
    "            [ 0.0, 0.0,   0.05,  0.0],\n",
    "            [ 0.0, 0.0,   0.0,   0.0],\n",
    "            [ 0.01, 0.0,  0.0,   0.0],\n",
    "            [ 0.0, 0.0,   0.0,   0.0],\n",
    "            [ 0.0, 0.0,   0.18,  0.0]\n",
    "        ], dtype=torch.float32)\n",
    "\n",
    "        self._bias = 0.1 * torch.tensor([0.2, -0.1, 0.3, -0.05], dtype=torch.float32)\n",
    "\n",
    "        self.x = torch.randn(num_examples, 12, dtype=torch.float32)\n",
    "        self.y = self.x @ self._W + self._bias\n",
    "        self.y = torch.argmax(self.y, dim=-1)\n",
    "\n",
    "    def show_answer(self, show=4):\n",
    "        from IPython.display import display\n",
    "\n",
    "        sp_W = sp.Matrix(self._W)\n",
    "        sp_x = [sp.Symbol(f\"x{i}\") for i in range(self._W.shape[0])]\n",
    "        sp_y = sp.Symbol(\"y\")\n",
    "        sp_func = sp.Function(\"argmax\")\n",
    "        sp_b = sp.Matrix(self._bias)\n",
    "\n",
    "        sp_x = sp.Matrix(sp_x).T\n",
    "        sp_b = sp.Matrix(sp_b).T\n",
    "\n",
    "        sp_eq = sp.Eq(sp_y, sp_func(sp_x @ sp_W + sp_b), evaluate=False)\n",
    "\n",
    "        print(\"True Pop Params\")\n",
    "        display(sp.Eq(sp.Symbol(\"W\"), sp_W, evaluate=False))\n",
    "        display(sp.Eq(sp.Symbol(\"b\"), sp_b, evaluate=False))\n",
    "        display(sp_eq)\n",
    "\n",
    "# Example usage\n",
    "data = Dataset()\n",
    "data.show_answer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab59a9cd-6b78-4188-bb88-6339c320bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a19fa6-c4a5-44b2-bdf3-03896fb6c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple NN 1 layer same shape\n",
    "# register gelu\n",
    "\n",
    "torch.gelu = torch.nn.GELU()\n",
    "x = torch.linspace(-10,10,100)\n",
    "y = torch.gelu(x)\n",
    "\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c05b76-b971-4789-b8cd-4d82b7f0aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperSimpleNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.W = torch.randn(12,4,dtype=torch.float32) * 0.001\n",
    "        self.b = torch.randn(1,4,dtype=torch.float32) * 1e-6\n",
    "        \n",
    "        self.W = torch.nn.Parameter(self.W)\n",
    "        self.b = torch.nn.Parameter(self.b)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = torch.gelu(x@self.W + self.b)\n",
    "        return out\n",
    "\n",
    "simple_model = SuperSimpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd42ce-b576-47c8-8d46-5f755e14d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"At init\")\n",
    "with torch.no_grad():\n",
    "    for p in simple_model.named_parameters():\n",
    "        display(sp.Eq(sp.Symbol(f\"{p[0]}_init\"), sp.Matrix(p[1]),evaluate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934072a8-d204-47a6-857a-3e88c3eab901",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_examples = data.x.to(\"cuda\")\n",
    "y_examples = data.y.to(\"cuda\")\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "@torch.compile\n",
    "def train(epochs:int = 100_000):\n",
    "    model = SuperSimpleNN()\n",
    "    model.to(\"cuda\")\n",
    "\n",
    "    from tqdm import tqdm\n",
    "    pbar = tqdm(range(epochs))\n",
    "    optim = torch.optim.AdamW(model.parameters(),weight_decay=1e-3)\n",
    "\n",
    "    for epoch in pbar:\n",
    "        out = model(x_examples)\n",
    "        loss = torch.nn.functional.cross_entropy(input = out, target = y_examples)\n",
    "    \n",
    "        if epoch % 10_000 == 0:\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "    \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbea2e04-80b6-4ba1-9bf6-6c6f4f2d88f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    response = torch.argmax(model(x_examples),dim=-1)\n",
    "    print(\"Score:k\",torch.sum(response==y_examples)*1.0)\n",
    "    \n",
    "    sp_Wresult = sp.Matrix(model.W.to(\"cpu\"))\n",
    "    sp_Bresult = sp.Matrix(model.b.to(\"cpu\"))\n",
    "    \n",
    "    display(sp.Eq(sp.Symbol(\"W_result\"), sp_Wresult,evaluate=False))\n",
    "    display(sp.Eq(sp.Symbol(\"B_result\"), sp_Bresult,evaluate=False))\n",
    "    \n",
    "    print(\"==========\")\n",
    "    sp_Wgrad = sp.Matrix(model.W.grad.to(\"cpu\"))\n",
    "    sp_bgrad = sp.Matrix(model.b.grad.to(\"cpu\"))\n",
    "\n",
    "    display(sp.Eq(sp.Symbol(\"Wgrad_result\"), sp_Wgrad,evaluate=False))\n",
    "    display(sp.Eq(sp.Symbol(\"Bgrad_result\"), sp_bgrad,evaluate=False))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959ff1cb-b0bb-4871-9d1b-b18892d9b8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
